username=zdk_user
hbase.key=1SE0zUSrgZ3KY7WPH04rfCkJ2aZYRjKE
hbase.id=eXRaYMFW21tY3ymQMbL6cQc97HLUdOSetnnc
hbase.zookeeper.parent=/hbase-unsecure

zookeeper.address=10.166.114.22,10.166.114.24,10.166.114.23,10.166.114.25,10.166.114.26,10.166.114.33,10.166.114.44

hadoop.key=oGKEZWt5JEil2iQC1Ac25YsN9p9aAvwC
hadoop.id=JOxYmGQODiBqoGFvMK15OJWAQ8qMoMRezDNV
hadoop.tmepDir=hdfs://tbds-10-166-114-44:8020/project/zdk_yunnan/

hdfs.tmp.dir=/project/zdk_yunnan/fk/my_tmp
## 末尾的“/”不能少
hdfs.output.dir=/project/zdk_yunnan/fk/my_hfile/

oracle.driver=oracle.jdbc.OracleDriver
oracle.url=jdbc:oracle:thin:@86.1.41.64:1521:orcl
oracle.user=ynfk_ywk
oracle.password=ynfkywk6089

hive.site.path=/usr/hdp/2.2.0.0-2041/spark/conf/hive-site.xml

relation.view=V_HIVE_TO_HBASE_RELATION_LJ2
relation.table=HIVE2HBASE.HIVE_TO_HBASE_RELATION_TEST

## 设置task数量
spark.task.num=500
## 申请的executor数量
spark.executor.instances=15
spark.executor.memory=12g
spark.executor.cores=2
## 并行数
spark.default.parallelism=300


## hbase表信息是否大写 add by 20191224
hbase.upper.case=1


